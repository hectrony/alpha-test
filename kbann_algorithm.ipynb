{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "YDzPz1D_q73o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import requests\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://archive.ics.uci.edu/static/public/508/qsar+oral+toxicity.zip'\n",
        "\n",
        "# downloading\n",
        "respuesta = requests.get(url)\n",
        "\n",
        "# verificando descarga\n",
        "if respuesta.status_code == 200:\n",
        "    # abriendo el archivo .zip desde repuesta\n",
        "    with zipfile.ZipFile(io.BytesIO(respuesta.content)) as archivo_zip:\n",
        "        # listando archivos\n",
        "        print(\"Archivos en el ZIP:\", archivo_zip.namelist())\n",
        "\n",
        "        # extrayendo archivo\n",
        "        nombre_csv = archivo_zip.namelist()[0]  # first file\n",
        "        with archivo_zip.open(nombre_csv) as archivo_csv:\n",
        "            # Cargar el CSV en un DataFrame de pandas\n",
        "            df = pd.read_csv(archivo_csv, sep= ';')\n",
        "            print(df.head())  # primeras filas del dataframe\n",
        "else:\n",
        "    print(\"Download ERROR\", respuesta.status_code)\n"
      ],
      "metadata": {
        "id": "WGC8Ut6PFrbS",
        "outputId": "bef01900-c3c1-4af4-bc8f-af0aab819847",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos en el ZIP: ['qsar_oral_toxicity.csv']\n",
            "   0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...  0.962  0.963  0.964  \\\n",
            "0  0    0    1    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "1  0    0    0    0    0    0    0    0    0    0  ...      0      0      1   \n",
            "2  0    0    0    0    0    0    0    1    0    0  ...      0      0      0   \n",
            "3  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "4  1    0    0    0    0    0    1    0    0    0  ...      0      0      0   \n",
            "\n",
            "   0.965  0.966  0.967  0.968  0.969  0.970  negative  \n",
            "0      0      0      0      0      0      0  negative  \n",
            "1      0      0      0      0      0      0  negative  \n",
            "2      0      0      0      0      0      0  negative  \n",
            "3      0      0      0      0      0      0  negative  \n",
            "4      0      0      1      0      0      0  negative  \n",
            "\n",
            "[5 rows x 1025 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading data\n",
        "datos = df\n",
        "\n",
        "# replace \"positive\" y \"negative\" for 1 and -1\n",
        "datos['negative'] = datos['negative'].replace({'positive': 1, 'negative': -1})\n",
        "\n",
        "# separating features and tags\n",
        "X = datos.iloc[:, :-1].values  # all columns, except last\n",
        "y = datos['negative'].values  # last column\n",
        "\n",
        "# Dividir en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "etpsrvSaHen5",
        "outputId": "9be2cbb1-8823-40ed-9e5d-1e36041f0383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-fb58b476f92c>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  datos['negative'] = datos['negative'].replace({'positive': 1, 'negative': -1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reglas_if_then(x):\n",
        "    # rules based in binaries features\n",
        "    if x[0] == 1 and x[1] == 0:\n",
        "        return 1\n",
        "    elif x[0] == 0 and x[1] == 1:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0  # no definied clasification\n",
        "\n",
        "# applying rules to training data for create initial tag volume\n",
        "y_train_reglas = np.array([reglas_if_then(x) for x in X_train])\n"
      ],
      "metadata": {
        "id": "fME7v6Xkr-Wg"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create KBANN model using Keras\n",
        "modelo = Sequential()\n",
        "modelo.add(Dense(10, input_dim=X.shape[1], activation='relu'))  # hide layer : 10 neuron\n",
        "modelo.add(Dense(1, activation='tanh'))  # out layer\n",
        "\n",
        "# compiling model\n",
        "modelo.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo con los datos preprocesados y las etiquetas definidas por las reglas si es necesario\n",
        "modelo.fit(X_train, y_train_reglas, epochs=100, batch_size=10)\n"
      ],
      "metadata": {
        "id": "-uCQMpVWsbhe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8b6857-f0f9-43b5-a92c-f850130bef83"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.1022\n",
            "Epoch 2/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9638 - loss: 0.0264\n",
            "Epoch 3/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9634 - loss: 0.0143\n",
            "Epoch 4/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 0.0083\n",
            "Epoch 5/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9648 - loss: 0.0061\n",
            "Epoch 6/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9677 - loss: 0.0043\n",
            "Epoch 7/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.0036\n",
            "Epoch 8/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9686 - loss: 0.0027\n",
            "Epoch 9/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9645 - loss: 0.0037\n",
            "Epoch 10/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 0.0025\n",
            "Epoch 11/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.0027\n",
            "Epoch 12/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9702 - loss: 0.0024\n",
            "Epoch 13/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9702 - loss: 0.0026\n",
            "Epoch 14/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0026\n",
            "Epoch 15/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9671 - loss: 0.0011\n",
            "Epoch 16/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9677 - loss: 0.0012\n",
            "Epoch 17/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.0011\n",
            "Epoch 18/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 3.7778e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 1.9531e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9699 - loss: 3.9978e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 2.5841e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 4.2461e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9642 - loss: 6.0130e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9657 - loss: 8.5639e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 8.3966e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 1.4185e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9702 - loss: 2.4290e-05\n",
            "Epoch 29/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 1.0596e-05\n",
            "Epoch 30/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 2.5546e-05\n",
            "Epoch 31/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9702 - loss: 1.3282e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 1.5814e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9717 - loss: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 3.4634e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 2.8255e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9658 - loss: 2.4604e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 7.4776e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 3.1989e-06\n",
            "Epoch 39/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 1.3033e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 2.8343e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 7.8361e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9625 - loss: 7.9165e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 8.2277e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 3.5835e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 1.1129e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9686 - loss: 1.2394e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 1.5902e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9699 - loss: 1.8835e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9647 - loss: 3.8557e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 1.7857e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9668 - loss: 5.2580e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 1.5302e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9681 - loss: 1.5460e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 7.1918e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9704 - loss: 4.9376e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9678 - loss: 1.0202e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9725 - loss: 6.1820e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9723 - loss: 3.8618e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9678 - loss: 5.6465e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 3.7328e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9724 - loss: 1.1247e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 1.8449e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 7.5892e-07\n",
            "Epoch 64/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9722 - loss: 1.0278e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 2.2349e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 8.8473e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9686 - loss: 1.7707e-07\n",
            "Epoch 68/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9699 - loss: 3.1072e-07\n",
            "Epoch 69/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9725 - loss: 1.8082e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9684 - loss: 4.0801e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.0016\n",
            "Epoch 72/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9684 - loss: 4.0460e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 1.9951e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9686 - loss: 4.6352e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 3.8984e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9686 - loss: 2.3059e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 4.3671e-07\n",
            "Epoch 78/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9673 - loss: 4.3845e-07\n",
            "Epoch 79/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9697 - loss: 3.5791e-07\n",
            "Epoch 80/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 1.5552e-07\n",
            "Epoch 81/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 1.4517e-07\n",
            "Epoch 82/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 1.1232e-07\n",
            "Epoch 83/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 7.0220e-08\n",
            "Epoch 84/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 5.4151e-08\n",
            "Epoch 85/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 1.0223e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9702 - loss: 3.6399e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9738 - loss: 3.1431e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 2.5219e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 6.2725e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9671 - loss: 4.6258e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 2.2218e-07\n",
            "Epoch 92/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 2.2479e-07\n",
            "Epoch 93/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 1.7976e-07\n",
            "Epoch 94/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 1.3244e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 5.2889e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 4.5706e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 8.8171e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 8.3773e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 1.0254e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 2.7244e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d9b254fa7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualizar_datos(X, y):\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "    plt.xlabel('Feature 2')\n",
        "    plt.ylabel('Feature 1')\n",
        "    plt.title('Training Data')\n",
        "    plt.show()\n",
        "\n",
        "visualizar_datos(X_train, y_train_reglas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "qDiTwI4_sjSW",
        "outputId": "09258caa-9a60-4d28-dc2a-f09a23a19944"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def comprobar_aprendizaje(nuevos_datos):\n",
        "    predicciones = modelo.predict(nuevos_datos)\n",
        "    return np.where(predicciones > 0, 1, -1)  # Clasificar como positivo o negativo\n",
        "\n",
        "# Ejemplo de nuevos datos para comprobar el aprendizaje del modelo\n",
        "nuevos_datos = np.array([[1, 0], [0, 1]])  # Cambia esto a tus nuevos datos binarios\n",
        "resultados = comprobar_aprendizaje(nuevos_datos)\n",
        "print(\"Resultados de clasificación:\", resultados)\n"
      ],
      "metadata": {
        "id": "AE1Rq8DDsuk1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "970a2c10-f2ba-4d3b-a9a9-5f617bb5d54d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_2\" is incompatible with the layer: expected axis -1 of input shape to have value 1024, but received input with shape (2, 2)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(2, 2), dtype=int64)\n  • training=False\n  • mask=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-b5fcef3701ad>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Ejemplo de nuevos datos para comprobar el aprendizaje del modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnuevos_datos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Cambia esto a tus nuevos datos binarios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresultados\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomprobar_aprendizaje\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuevos_datos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resultados de clasificación:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultados\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-b5fcef3701ad>\u001b[0m in \u001b[0;36mcomprobar_aprendizaje\u001b[0;34m(nuevos_datos)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcomprobar_aprendizaje\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuevos_datos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpredicciones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuevos_datos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicciones\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Clasificar como positivo o negativo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Ejemplo de nuevos datos para comprobar el aprendizaje del modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 }:\n\u001b[0;32m--> 227\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    228\u001b[0m                         \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                         \u001b[0;34mf\"incompatible with the layer: expected axis {axis} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_2\" is incompatible with the layer: expected axis -1 of input shape to have value 1024, but received input with shape (2, 2)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(2, 2), dtype=int64)\n  • training=False\n  • mask=None"
          ]
        }
      ]
    }
  ]
}